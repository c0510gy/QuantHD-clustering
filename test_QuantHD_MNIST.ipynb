{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hd_clustering\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 10000\n",
    "MAX_SAMPLES = 10000\n",
    "DATA_SET = 'mnist'\n",
    "DATA_LOC = './Conventional_Data/'\n",
    "# FEATURES = None\n",
    "# CLUSTERS = None\n",
    "BITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset mnist from mnist\n",
      "Loading train data... train data of shape (60000, 784) loaded\n",
      "Loading test data...  test  data of shape (10000, 784) loaded\n",
      "Data Loaded. Num of features = 784 Num of Classes = 10"
     ]
    }
   ],
   "source": [
    "dl = hd_clustering.Dataloader(dir=DATA_SET, dataset=DATA_SET, data_loc=DATA_LOC)\n",
    "nFeatures, nClasses, traindata, trainlabels, testdata, testlabels = dl.getParam()\n",
    "traindata = traindata[:MAX_SAMPLES]\n",
    "trainlabels = trainlabels[:MAX_SAMPLES]\n",
    "testdata = testdata[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = nClasses\n",
    "features = traindata.shape[1]\n",
    "model = hd_clustering.QuantHD_cluster(clusters, features, BITS, dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7840000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "6\n",
      "5\n",
      "3\n",
      "7\n",
      "4\n",
      "0\n",
      "1\n",
      "1\n",
      "tensor([[-0.5117, -0.2157, -0.3373,  ...,  0.4780, -0.0243,  0.2027],\n",
      "        [-0.4297, -0.2544,  0.3271,  ...,  0.5304,  0.7683, -0.0086],\n",
      "        [-0.3462,  0.7448,  0.3567,  ...,  0.8729, -0.1742,  0.0602],\n",
      "        ...,\n",
      "        [ 0.1485,  0.3300, -0.1469,  ...,  0.8356, -0.1201,  0.1384],\n",
      "        [-0.4784, -0.1690,  0.2599,  ..., -0.0583,  0.2981,  0.6518],\n",
      "        [-0.5143, -0.1182, -0.5104,  ..., -0.0920, -0.0401,  0.7150]])\n",
      "tensor([[1., 2., 1.,  ..., 6., 3., 5.],\n",
      "        [1., 2., 6.,  ..., 7., 7., 3.],\n",
      "        [1., 7., 6.,  ..., 7., 2., 4.],\n",
      "        ...,\n",
      "        [4., 6., 3.,  ..., 7., 3., 4.],\n",
      "        [1., 2., 5.,  ..., 3., 5., 7.],\n",
      "        [1., 3., 1.,  ..., 3., 3., 7.]])\n",
      "0 0.1349\n",
      "1 0.1489\n",
      "2 0.153\n",
      "3 0.1584\n",
      "4 0.1633\n",
      "5 0.166\n",
      "6 0.17\n",
      "7 0.1739\n",
      "8 0.1766\n",
      "9 0.1777\n",
      "10 0.1787\n",
      "11 0.1788\n",
      "12 0.1793\n",
      "13 0.1799\n",
      "14 0.1806\n",
      "15 0.1808\n",
      "16 0.1814\n",
      "17 0.1819\n",
      "18 0.1821\n",
      "19 0.1823\n",
      "20 0.1826\n",
      "21 0.1828\n",
      "22 0.1829\n",
      "23 0.1833\n",
      "24 0.1836\n",
      "25 0.1837\n",
      "26 0.1837\n",
      "27 0.1837\n",
      "28 0.1837\n",
      "29 0.1837\n",
      "30 0.1837\n",
      "31 0.1837\n",
      "32 0.1837\n",
      "33 0.1837\n",
      "34 0.1837\n",
      "35 0.1837\n",
      "36 0.1837\n",
      "37 0.1837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      2\u001b[0m   model\u001b[38;5;241m.\u001b[39mfit(torch\u001b[38;5;241m.\u001b[39mtensor(traindata\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, init_model\u001b[38;5;241m=\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m epoch), labels\u001b[38;5;241m=\u001b[39mtrainlabels)\n\u001b[0;32m----> 4\u001b[0m   ypred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraindata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   train_acc \u001b[38;5;241m=\u001b[39m (ypred \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(trainlabels))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(ypred)\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(epoch, train_acc)\n",
      "File \u001b[0;32m~/git_reps/QuantHD-clustering/febhd_clustering/quanthd.py:95\u001b[0m, in \u001b[0;36mQuantHD_cluster.__call__\u001b[0;34m(self, x, encoded)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x : torch\u001b[38;5;241m.\u001b[39mTensor, encoded : \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    Returns the predicted cluster of each data point in x.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m        Has size `(n?,)`.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/git_reps/QuantHD-clustering/febhd_clustering/quanthd.py:171\u001b[0m, in \u001b[0;36mQuantHD_cluster.scores\u001b[0;34m(self, x, encoded)\u001b[0m\n\u001b[1;32m    168\u001b[0m h \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m encoded \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(x)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m#return 1 - torch.cdist(h.sign(), self.quantized_model.sign(), 0)/self.dim\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantized_model)\n",
      "File \u001b[0;32m~/git_reps/QuantHD-clustering/febhd_clustering/quanthd.py:19\u001b[0m, in \u001b[0;36mquantize\u001b[0;34m(X, bits)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# notice the axis along which to normalize is always the last one\u001b[39;00m\n\u001b[1;32m     18\u001b[0m nX \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mcdf(stats\u001b[38;5;241m.\u001b[39mzscore(X, axis\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m nX \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdigitize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#print(\"Max and min bin value:\", np.max(nX), np.min(nX))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#print(\"Quantized from \", X)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#print(\"To\", nX)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m nX \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(nX\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdigitize\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/git_reps/QuantHD-clustering/venv/lib/python3.8/site-packages/numpy/lib/function_base.py:5507\u001b[0m, in \u001b[0;36mdigitize\u001b[0;34m(x, bins, right)\u001b[0m\n\u001b[1;32m   5505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m-\u001b[39m _nx\u001b[38;5;241m.\u001b[39msearchsorted(bins[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], x, side\u001b[38;5;241m=\u001b[39mside)\n\u001b[1;32m   5506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/git_reps/QuantHD-clustering/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1387\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \n\u001b[1;32m   1386\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearchsorted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git_reps/QuantHD-clustering/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch), labels=trainlabels)\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 289.,  703., 1141., 1103., 1227., 1437.,  989.,  961., 1430.,  720.])\n",
      "0 0.1184\n",
      "tensor([ 301.,  935., 1085., 1375., 1148., 1386., 1054., 1162.,  828.,  726.])\n",
      "1 0.1155\n",
      "tensor([ 359.,  960.,  961., 1437., 1139., 1149., 1017., 1509.,  770.,  699.])\n",
      "2 0.1112\n",
      "tensor([ 419.,  996.,  908., 1451., 1152., 1024., 1006., 1618.,  719.,  707.])\n",
      "3 0.1117\n",
      "tensor([ 459., 1006.,  900., 1452., 1119.,  944., 1019., 1658.,  699.,  744.])\n",
      "4 0.1144\n",
      "tensor([ 504., 1013.,  940., 1440., 1056.,  915., 1035., 1647.,  688.,  762.])\n",
      "5 0.1178\n",
      "tensor([ 545., 1017.,  973., 1424., 1015.,  912., 1046., 1625.,  685.,  758.])\n",
      "6 0.1233\n",
      "tensor([ 576., 1021., 1005., 1397.,  982.,  936., 1061., 1589.,  679.,  754.])\n",
      "7 0.1289\n",
      "tensor([ 595., 1027., 1025., 1375.,  948.,  994., 1067., 1553.,  675.,  741.])\n",
      "8 0.1334\n",
      "tensor([ 612., 1021., 1049., 1366.,  912., 1040., 1069., 1534.,  667.,  730.])\n",
      "9 0.1361\n",
      "tensor([ 618., 1018., 1071., 1365.,  883., 1064., 1072., 1524.,  667.,  718.])\n",
      "10 0.1383\n",
      "tensor([ 618., 1016., 1080., 1350.,  873., 1089., 1075., 1515.,  675.,  709.])\n",
      "11 0.1389\n",
      "tensor([ 619., 1019., 1082., 1329.,  869., 1103., 1068., 1513.,  691.,  707.])\n",
      "12 0.1391\n",
      "tensor([ 621., 1019., 1083., 1317.,  864., 1111., 1059., 1508.,  711.,  707.])\n",
      "13 0.1396\n",
      "tensor([ 623., 1020., 1082., 1300.,  866., 1117., 1058., 1499.,  729.,  706.])\n",
      "14 0.1402\n",
      "tensor([ 624., 1019., 1080., 1288.,  867., 1123., 1056., 1492.,  745.,  706.])\n",
      "15 0.1405\n",
      "tensor([ 624., 1014., 1073., 1267.,  873., 1137., 1053., 1483.,  771.,  705.])\n",
      "16 0.1413\n",
      "tensor([ 625.,  998., 1071., 1239.,  877., 1139., 1051., 1480.,  816.,  704.])\n",
      "17 0.1415\n",
      "tensor([ 625.,  981., 1067., 1209.,  875., 1142., 1052., 1484.,  862.,  703.])\n",
      "18 0.1412\n",
      "tensor([ 625.,  941., 1064., 1180.,  876., 1146., 1053., 1485.,  927.,  703.])\n",
      "19 0.1407\n",
      "tensor([ 629.,  920., 1062., 1152.,  874., 1150., 1053., 1485.,  971.,  704.])\n",
      "20 0.1403\n",
      "tensor([ 634.,  893., 1062., 1126.,  871., 1148., 1051., 1485., 1026.,  704.])\n",
      "21 0.1406\n",
      "tensor([ 637.,  887., 1060., 1110.,  869., 1148., 1050., 1483., 1050.,  706.])\n",
      "22 0.1406\n",
      "tensor([ 636.,  881., 1059., 1101.,  871., 1147., 1047., 1484., 1068.,  706.])\n",
      "23 0.1406\n",
      "tensor([ 637.,  874., 1060., 1092.,  870., 1152., 1047., 1483., 1078.,  707.])\n",
      "24 0.1407\n",
      "tensor([ 637.,  867., 1060., 1085.,  869., 1156., 1048., 1482., 1089.,  707.])\n",
      "25 0.1407\n",
      "tensor([ 637.,  863., 1058., 1086.,  869., 1157., 1049., 1482., 1092.,  707.])\n",
      "26 0.1407\n",
      "tensor([ 636.,  854., 1057., 1085.,  869., 1158., 1049., 1482., 1103.,  707.])\n",
      "27 0.1407\n",
      "tensor([ 637.,  853., 1055., 1085.,  868., 1157., 1049., 1483., 1106.,  707.])\n",
      "28 0.1408\n",
      "tensor([ 636.,  849., 1056., 1084.,  867., 1157., 1049., 1482., 1113.,  707.])\n",
      "29 0.1408\n",
      "tensor([ 635.,  846., 1056., 1083.,  867., 1157., 1049., 1482., 1118.,  707.])\n",
      "30 0.141\n",
      "tensor([ 635.,  840., 1056., 1083.,  867., 1158., 1049., 1482., 1123.,  707.])\n",
      "31 0.1412\n",
      "tensor([ 635.,  835., 1056., 1082.,  866., 1160., 1049., 1482., 1128.,  707.])\n",
      "32 0.141\n",
      "tensor([ 635.,  831., 1056., 1081.,  866., 1159., 1049., 1482., 1134.,  707.])\n",
      "33 0.141\n",
      "tensor([ 635.,  827., 1057., 1077.,  866., 1158., 1049., 1482., 1142.,  707.])\n",
      "34 0.141\n",
      "tensor([ 635.,  827., 1057., 1077.,  867., 1157., 1049., 1482., 1142.,  707.])\n",
      "35 0.1411\n",
      "tensor([ 635.,  827., 1057., 1079.,  867., 1157., 1048., 1482., 1141.,  707.])\n",
      "36 0.1412\n",
      "tensor([ 635.,  827., 1057., 1080.,  867., 1159., 1048., 1482., 1138.,  707.])\n",
      "37 0.1413\n",
      "tensor([ 635.,  827., 1057., 1082.,  867., 1160., 1048., 1482., 1136.,  706.])\n",
      "38 0.1413\n",
      "tensor([ 635.,  827., 1057., 1085.,  867., 1159., 1048., 1482., 1133.,  707.])\n",
      "39 0.1413\n",
      "tensor([ 635.,  826., 1058., 1086.,  867., 1159., 1048., 1481., 1133.,  707.])\n",
      "40 0.1414\n",
      "tensor([ 635.,  825., 1058., 1088.,  867., 1157., 1048., 1482., 1133.,  707.])\n",
      "41 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "42 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "43 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "44 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "45 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "46 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "47 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "48 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "49 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "50 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1918\n",
      "1 0.1994\n",
      "2 0.199\n",
      "3 0.2009\n",
      "4 0.2058\n",
      "5 0.2091\n",
      "6 0.2126\n",
      "7 0.2139\n",
      "8 0.215\n",
      "9 0.2166\n",
      "10 0.2167\n",
      "11 0.217\n",
      "12 0.2172\n",
      "13 0.2172\n",
      "14 0.2179\n",
      "15 0.2182\n",
      "16 0.218\n",
      "17 0.2181\n",
      "18 0.2182\n",
      "19 0.2187\n",
      "20 0.2197\n",
      "21 0.2206\n",
      "22 0.2218\n",
      "23 0.223\n",
      "24 0.2242\n",
      "25 0.2258\n",
      "26 0.2274\n",
      "27 0.2279\n",
      "28 0.2284\n",
      "29 0.2288\n",
      "30 0.2291\n",
      "31 0.2287\n",
      "32 0.2288\n",
      "33 0.2289\n",
      "34 0.2288\n",
      "35 0.2287\n",
      "36 0.2286\n",
      "37 0.2285\n",
      "38 0.2286\n",
      "39 0.2287\n",
      "40 0.2286\n",
      "41 0.2287\n",
      "42 0.2294\n",
      "43 0.2296\n",
      "44 0.2299\n",
      "45 0.2301\n",
      "46 0.2305\n",
      "47 0.2306\n",
      "48 0.2304\n",
      "49 0.2303\n",
      "50 0.2306\n",
      "51 0.2308\n",
      "52 0.2307\n",
      "53 0.2306\n",
      "54 0.2306\n",
      "55 0.2306\n",
      "56 0.2306\n",
      "57 0.2309\n",
      "58 0.2309\n",
      "59 0.2309\n",
      "60 0.2306\n",
      "61 0.2304\n",
      "62 0.2302\n",
      "63 0.2302\n",
      "64 0.23\n",
      "65 0.23\n",
      "66 0.23\n",
      "67 0.23\n",
      "68 0.23\n",
      "69 0.2299\n",
      "70 0.2301\n",
      "71 0.2301\n",
      "72 0.2299\n",
      "73 0.2299\n",
      "74 0.2299\n",
      "75 0.2299\n",
      "76 0.2299\n",
      "77 0.2299\n",
      "78 0.2299\n",
      "79 0.2299\n",
      "80 0.2299\n",
      "81 0.2299\n",
      "82 0.2299\n",
      "83 0.2299\n",
      "84 0.2299\n",
      "85 0.2299\n",
      "86 0.2299\n",
      "87 0.2299\n",
      "88 0.2299\n",
      "89 0.2299\n",
      "90 0.2299\n",
      "91 0.2299\n",
      "92 0.2299\n",
      "93 0.2299\n",
      "94 0.2299\n",
      "95 0.2299\n",
      "96 0.2299\n",
      "97 0.2299\n",
      "98 0.2299\n",
      "99 0.2299\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.06\n",
      "1 0.011\n",
      "2 0.011\n",
      "3 0.019\n",
      "4 0.024\n",
      "5 0.028\n",
      "6 0.028\n",
      "7 0.028\n",
      "8 0.028\n",
      "9 0.027\n",
      "10 0.029\n",
      "11 0.029\n",
      "12 0.03\n",
      "13 0.031\n",
      "14 0.032\n",
      "15 0.032\n",
      "16 0.032\n",
      "17 0.032\n",
      "18 0.032\n",
      "19 0.033\n",
      "20 0.034\n",
      "21 0.034\n",
      "22 0.034\n",
      "23 0.034\n",
      "24 0.037\n",
      "25 0.037\n",
      "26 0.037\n",
      "27 0.037\n",
      "28 0.037\n",
      "29 0.037\n",
      "30 0.037\n",
      "31 0.037\n",
      "32 0.037\n",
      "33 0.037\n",
      "34 0.037\n",
      "35 0.037\n",
      "36 0.037\n",
      "37 0.037\n",
      "38 0.037\n",
      "39 0.038\n",
      "40 0.038\n",
      "41 0.038\n",
      "42 0.038\n",
      "43 0.038\n",
      "44 0.038\n",
      "45 0.038\n",
      "46 0.038\n",
      "47 0.039\n",
      "48 0.039\n",
      "49 0.039\n",
      "50 0.039\n",
      "51 0.039\n",
      "52 0.039\n",
      "53 0.039\n",
      "54 0.039\n",
      "55 0.039\n",
      "56 0.039\n",
      "57 0.039\n",
      "58 0.039\n",
      "59 0.039\n",
      "60 0.04\n",
      "61 0.04\n",
      "62 0.04\n",
      "63 0.04\n",
      "64 0.04\n",
      "65 0.04\n",
      "66 0.04\n",
      "67 0.04\n",
      "68 0.04\n",
      "69 0.04\n",
      "70 0.04\n",
      "71 0.04\n",
      "72 0.04\n",
      "73 0.04\n",
      "74 0.04\n",
      "75 0.04\n",
      "76 0.04\n",
      "77 0.04\n",
      "78 0.041\n",
      "79 0.041\n",
      "80 0.041\n",
      "81 0.041\n",
      "82 0.041\n",
      "83 0.041\n",
      "84 0.041\n",
      "85 0.041\n",
      "86 0.041\n",
      "87 0.041\n",
      "88 0.041\n",
      "89 0.041\n",
      "90 0.041\n",
      "91 0.041\n",
      "92 0.041\n",
      "93 0.041\n",
      "94 0.042\n",
      "95 0.042\n",
      "96 0.042\n",
      "97 0.042\n",
      "98 0.042\n",
      "99 0.042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.077\n",
      "1 0.053\n",
      "2 0.039\n",
      "3 0.028\n",
      "4 0.025\n",
      "5 0.024\n",
      "6 0.021\n",
      "7 0.024\n",
      "8 0.023\n",
      "9 0.022\n",
      "10 0.021\n",
      "11 0.021\n",
      "12 0.021\n",
      "13 0.02\n",
      "14 0.019\n",
      "15 0.018\n",
      "16 0.016\n",
      "17 0.016\n",
      "18 0.016\n",
      "19 0.016\n",
      "20 0.016\n",
      "21 0.016\n",
      "22 0.016\n",
      "23 0.016\n",
      "24 0.016\n",
      "25 0.016\n",
      "26 0.017\n",
      "27 0.017\n",
      "28 0.017\n",
      "29 0.017\n",
      "30 0.017\n",
      "31 0.017\n",
      "32 0.017\n",
      "33 0.017\n",
      "34 0.017\n",
      "35 0.016\n",
      "36 0.016\n",
      "37 0.016\n",
      "38 0.016\n",
      "39 0.016\n",
      "40 0.017\n",
      "41 0.017\n",
      "42 0.017\n",
      "43 0.017\n",
      "44 0.017\n",
      "45 0.017\n",
      "46 0.017\n",
      "47 0.017\n",
      "48 0.017\n",
      "49 0.017\n",
      "50 0.017\n",
      "51 0.017\n",
      "52 0.017\n",
      "53 0.017\n",
      "54 0.017\n",
      "55 0.017\n",
      "56 0.017\n",
      "57 0.017\n",
      "58 0.017\n",
      "59 0.017\n",
      "60 0.017\n",
      "61 0.017\n",
      "62 0.017\n",
      "63 0.017\n",
      "64 0.017\n",
      "65 0.017\n",
      "66 0.017\n",
      "67 0.017\n",
      "68 0.017\n",
      "69 0.017\n",
      "70 0.017\n",
      "71 0.017\n",
      "72 0.018\n",
      "73 0.018\n",
      "74 0.018\n",
      "75 0.018\n",
      "76 0.018\n",
      "77 0.018\n",
      "78 0.018\n",
      "79 0.018\n",
      "80 0.018\n",
      "81 0.018\n",
      "82 0.018\n",
      "83 0.018\n",
      "84 0.018\n",
      "85 0.018\n",
      "86 0.018\n",
      "87 0.018\n",
      "88 0.018\n",
      "89 0.018\n",
      "90 0.018\n",
      "91 0.018\n",
      "92 0.018\n",
      "93 0.018\n",
      "94 0.018\n",
      "95 0.018\n",
      "96 0.018\n",
      "97 0.018\n",
      "98 0.018\n",
      "99 0.018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model(torch.tensor(traindata.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 2, 9, 4, 6, 3, 5, 8, 5, 9, 8, 7, 1, 3, 5, 6, 8, 4, 3, 6, 9, 2, 9, 4,\n",
       "        3, 8, 6, 8, 1, 9, 0, 4, 3, 6, 2, 7, 3, 2, 6, 3, 5, 4, 6, 6, 0, 6, 4, 7,\n",
       "        1, 8, 8, 2, 6, 9, 6, 4, 1, 6, 6, 4, 1, 9, 3, 2, 3, 7, 3, 4, 1, 1, 5, 9,\n",
       "        5, 3, 8, 2, 0, 4, 4, 9, 1, 2, 3, 3, 6, 4, 1, 6, 1, 9, 3, 6, 6, 3, 4, 2,\n",
       "        6, 4, 8, 4, 0, 6, 5, 6, 5, 4, 3, 8, 1, 3, 6, 8, 5, 4, 2, 9, 6, 8, 2, 2,\n",
       "        1, 1, 4, 6, 5, 4, 3, 9, 5, 3, 8, 9, 5, 6, 0, 8, 8, 4, 1, 9, 6, 9, 6, 4,\n",
       "        0, 7, 4, 3, 6, 8, 5, 3, 5, 6, 6, 3, 2, 8, 1, 4, 8, 8, 6, 9, 9, 3, 9, 6,\n",
       "        4, 2, 6, 4, 6, 7, 5, 7, 6, 4, 2, 8, 5, 8, 1, 6, 5, 6, 3, 8, 6, 0, 5, 7,\n",
       "        2, 6, 6, 6, 6, 4, 1, 6, 5, 4, 4, 8, 3, 4, 1, 8, 5, 1, 1, 5, 5, 3, 6, 8,\n",
       "        1, 9, 3, 2, 1, 3, 1, 6, 8, 8, 6, 6, 1, 1, 6, 5, 3, 3, 1, 8, 7, 9, 3, 7,\n",
       "        5, 3, 8, 6, 1, 4, 1, 6, 5, 1, 6, 5, 5, 3, 1, 8, 4, 9, 6, 7, 2, 3, 2, 6,\n",
       "        6, 4, 1, 6, 6, 4, 5, 9, 6, 7, 3, 9, 5, 3, 3, 8, 6, 8, 6, 1, 1, 6, 3, 7,\n",
       "        6, 9, 5, 8, 3, 2, 9, 4, 2, 9, 1, 3, 4, 6, 3, 2, 6, 6, 1, 6, 3, 4, 5, 3,\n",
       "        0, 6, 9, 4, 1, 3, 4, 9, 1, 8, 6, 3, 6, 3, 2, 8, 2, 9, 8, 3, 1, 1, 6, 7,\n",
       "        6, 6, 9, 3, 1, 8, 6, 4, 6, 4, 8, 2, 4, 6, 6, 4, 1, 6, 6, 4, 8, 4, 5, 2,\n",
       "        5, 8, 6, 9, 6, 3, 5, 3, 5, 9, 5, 6, 6, 9, 6, 3, 5, 6, 0, 9, 6, 3, 5, 6,\n",
       "        6, 3, 1, 6, 3, 6, 4, 2, 8, 4, 5, 3, 8, 4, 5, 2, 3, 3, 9, 7, 1, 8, 5, 7,\n",
       "        5, 9, 4, 6, 6, 9, 3, 4, 4, 7, 7, 6, 8, 3, 6, 6, 0, 8, 6, 2, 6, 1, 3, 3,\n",
       "        0, 8, 6, 2, 6, 7, 6, 4, 1, 6, 6, 4, 5, 4, 1, 4, 4, 3, 5, 2, 1, 2, 5, 4,\n",
       "        4, 2, 1, 6, 6, 9, 2, 7, 1, 3, 4, 6, 1, 4, 5, 6, 5, 2, 2, 4, 6, 2, 6, 8,\n",
       "        1, 9, 6, 0, 5, 2, 1, 9, 0, 2, 8, 4, 4, 3, 1, 8, 2, 4, 3, 4, 6, 9, 5, 4,\n",
       "        8, 6, 3, 4, 4, 4, 4, 4, 6, 7, 8, 2, 1, 3, 6, 2, 6, 6, 6, 7, 1, 9, 1, 7,\n",
       "        0, 9, 0, 9, 0, 4, 3, 4, 3, 7, 4, 4, 0, 9, 2, 7, 8, 4, 8, 3, 8, 8, 6, 2,\n",
       "        5, 4, 1, 2, 5, 8, 0, 4, 4, 8, 6, 3, 6, 3, 6, 6, 4, 9, 3, 4, 5, 4, 5, 4,\n",
       "        6, 2, 3, 7, 6, 8, 1, 4, 3, 9, 6, 4, 4, 9, 6, 2, 3, 4, 1, 9, 1, 3, 3, 6,\n",
       "        6, 9, 1, 2, 5, 9, 9, 3, 6, 4, 6, 4, 1, 8, 7, 4, 6, 6, 5, 3, 1, 9, 1, 3,\n",
       "        6, 2, 9, 6, 1, 8, 5, 9, 6, 2, 6, 9, 6, 4, 5, 2, 6, 4, 3, 8, 4, 8, 4, 9,\n",
       "        5, 3, 5, 6, 8, 7, 6, 9, 2, 4, 3, 4, 3, 9, 1, 9, 6, 3, 3, 7, 1, 2, 1, 4,\n",
       "        3, 3, 5, 8, 5, 6, 5, 2, 9, 3, 6, 6, 3, 4, 6, 6, 5, 2, 1, 4, 6, 4, 5, 8,\n",
       "        4, 9, 4, 2, 9, 3, 2, 6, 1, 4, 6, 6, 5, 2, 5, 4, 2, 3, 5, 8, 3, 9, 6, 2,\n",
       "        5, 3, 1, 6, 6, 4, 0, 6, 6, 9, 6, 8, 4, 2, 0, 3, 1, 3, 5, 3, 8, 9, 9, 2,\n",
       "        6, 2, 5, 4, 1, 9, 6, 2, 8, 6, 6, 9, 6, 2, 4, 3, 1, 4, 3, 6, 6, 4, 4, 8,\n",
       "        1, 4, 6, 2, 6, 6, 2, 7, 3, 4, 6, 4, 5, 2, 6, 4, 8, 3, 6, 2, 3, 8, 2, 4,\n",
       "        1, 6, 3, 6, 4, 9, 6, 2, 6, 9, 3, 6, 9, 2, 6, 4, 5, 4, 3, 8, 6, 4, 4, 2,\n",
       "        3, 4, 2, 6, 6, 4, 6, 4, 6, 2, 6, 9, 1, 3, 8, 4, 8, 4, 9, 4, 1, 2, 5, 6,\n",
       "        8, 3, 1, 8, 2, 2, 1, 9, 6, 2, 3, 9, 3, 6, 6, 9, 8, 8, 4, 2, 2, 8, 0, 0,\n",
       "        5, 4, 1, 8, 6, 2, 5, 4, 1, 2, 8, 8, 5, 9, 8, 7, 6, 3, 1, 6, 4, 4, 1, 6,\n",
       "        6, 2, 8, 4, 5, 2, 6, 8, 9, 9, 6, 7, 6, 3, 2, 2, 6, 4, 0, 2, 6, 8, 1, 6,\n",
       "        8, 4, 9, 7, 3, 2, 4, 4, 5, 7, 5, 4, 1, 4, 9, 2, 6, 6, 6, 2, 6, 9, 6, 7,\n",
       "        5, 9, 4, 3, 6, 4, 6, 3, 3, 9, 4, 7, 4, 2, 6, 4, 1, 8, 6, 3, 8, 2, 3, 4,\n",
       "        1, 4, 6, 4, 7, 2, 1, 9, 6, 6, 1, 9, 6, 3, 0, 8, 4, 3, 5, 2, 6, 6, 5, 8,\n",
       "        1, 7, 3, 9, 9, 2, 9, 6, 8, 4, 6, 9, 3, 2, 1, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bf9375872625b9969ad2a164b0e1bb1ff57dc43ce6d3e9b7d00df6c4b93696e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
