{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hd_clustering\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 10000\n",
    "MAX_SAMPLES = 200\n",
    "DATA_SET = 'face_full'\n",
    "DATA_LOC = './Conventional_Data/'\n",
    "# FEATURES = None\n",
    "# CLUSTERS = None\n",
    "BITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset face_full from face_full\n",
      "Loading train data... train data of shape (522441, 608) loaded\n",
      "Loading test data...  test  data of shape (2494, 608) loaded\n",
      "Data Loaded. Num of features = 608 Num of Classes = 2"
     ]
    }
   ],
   "source": [
    "dl = hd_clustering.Dataloader(dir=DATA_SET, dataset=DATA_SET, data_loc=DATA_LOC)\n",
    "nFeatures, nClasses, traindata, trainlabels, testdata, testlabels = dl.getParam()\n",
    "traindata = traindata[:MAX_SAMPLES]\n",
    "trainlabels = trainlabels[:MAX_SAMPLES]\n",
    "testdata = testdata[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = nClasses\n",
    "features = traindata.shape[1]\n",
    "model = hd_clustering.QuantHD_cluster(clusters, features, BITS, dim=DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "90 torch.Size([10000])\n",
      "[0 1 0 1 1 0 0 0 1 0] tensor([0.3697, 0.3744, 0.3749, 0.3800, 0.3793, 0.3725, 0.3748, 0.3819, 0.3714,\n",
      "        0.3695])\n",
      "0 0.425\n",
      "1 0.425\n",
      "2 0.425\n",
      "3 0.425\n",
      "4 0.425\n",
      "5 0.425\n",
      "6 0.425\n",
      "7 0.425\n",
      "8 0.425\n",
      "9 0.425\n",
      "10 0.425\n",
      "11 0.425\n",
      "12 0.425\n",
      "13 0.425\n",
      "14 0.425\n",
      "15 0.425\n",
      "16 0.425\n",
      "17 0.425\n",
      "18 0.425\n",
      "19 0.425\n",
      "20 0.425\n",
      "21 0.425\n",
      "22 0.425\n",
      "23 0.425\n",
      "24 0.425\n",
      "25 0.425\n",
      "26 0.425\n",
      "27 0.425\n",
      "28 0.425\n",
      "29 0.425\n",
      "30 0.425\n",
      "31 0.425\n",
      "32 0.425\n",
      "33 0.425\n",
      "34 0.425\n",
      "35 0.425\n",
      "36 0.425\n",
      "37 0.425\n",
      "38 0.425\n",
      "39 0.425\n",
      "40 0.425\n",
      "41 0.425\n",
      "42 0.425\n",
      "43 0.425\n",
      "44 0.425\n",
      "45 0.425\n",
      "46 0.425\n",
      "47 0.425\n",
      "48 0.425\n",
      "49 0.425\n",
      "50 0.425\n",
      "51 0.425\n",
      "52 0.425\n",
      "53 0.425\n",
      "54 0.425\n",
      "55 0.425\n",
      "56 0.425\n",
      "57 0.425\n",
      "58 0.425\n",
      "59 0.425\n",
      "60 0.425\n",
      "61 0.425\n",
      "62 0.425\n",
      "63 0.425\n",
      "64 0.425\n",
      "65 0.425\n",
      "66 0.425\n",
      "67 0.425\n",
      "68 0.425\n",
      "69 0.425\n",
      "70 0.425\n",
      "71 0.425\n",
      "72 0.425\n",
      "73 0.425\n",
      "74 0.425\n",
      "75 0.425\n",
      "76 0.425\n",
      "77 0.425\n",
      "78 0.425\n",
      "79 0.425\n",
      "80 0.425\n",
      "81 0.425\n",
      "82 0.425\n",
      "83 0.425\n",
      "84 0.425\n",
      "85 0.425\n",
      "86 0.425\n",
      "87 0.425\n",
      "88 0.425\n",
      "89 0.425\n",
      "90 0.425\n",
      "91 0.425\n",
      "92 0.425\n",
      "93 0.425\n",
      "94 0.425\n",
      "95 0.425\n",
      "96 0.425\n",
      "97 0.425\n",
      "98 0.425\n",
      "99 0.425\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch), labels=trainlabels)\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 289.,  703., 1141., 1103., 1227., 1437.,  989.,  961., 1430.,  720.])\n",
      "0 0.1184\n",
      "tensor([ 301.,  935., 1085., 1375., 1148., 1386., 1054., 1162.,  828.,  726.])\n",
      "1 0.1155\n",
      "tensor([ 359.,  960.,  961., 1437., 1139., 1149., 1017., 1509.,  770.,  699.])\n",
      "2 0.1112\n",
      "tensor([ 419.,  996.,  908., 1451., 1152., 1024., 1006., 1618.,  719.,  707.])\n",
      "3 0.1117\n",
      "tensor([ 459., 1006.,  900., 1452., 1119.,  944., 1019., 1658.,  699.,  744.])\n",
      "4 0.1144\n",
      "tensor([ 504., 1013.,  940., 1440., 1056.,  915., 1035., 1647.,  688.,  762.])\n",
      "5 0.1178\n",
      "tensor([ 545., 1017.,  973., 1424., 1015.,  912., 1046., 1625.,  685.,  758.])\n",
      "6 0.1233\n",
      "tensor([ 576., 1021., 1005., 1397.,  982.,  936., 1061., 1589.,  679.,  754.])\n",
      "7 0.1289\n",
      "tensor([ 595., 1027., 1025., 1375.,  948.,  994., 1067., 1553.,  675.,  741.])\n",
      "8 0.1334\n",
      "tensor([ 612., 1021., 1049., 1366.,  912., 1040., 1069., 1534.,  667.,  730.])\n",
      "9 0.1361\n",
      "tensor([ 618., 1018., 1071., 1365.,  883., 1064., 1072., 1524.,  667.,  718.])\n",
      "10 0.1383\n",
      "tensor([ 618., 1016., 1080., 1350.,  873., 1089., 1075., 1515.,  675.,  709.])\n",
      "11 0.1389\n",
      "tensor([ 619., 1019., 1082., 1329.,  869., 1103., 1068., 1513.,  691.,  707.])\n",
      "12 0.1391\n",
      "tensor([ 621., 1019., 1083., 1317.,  864., 1111., 1059., 1508.,  711.,  707.])\n",
      "13 0.1396\n",
      "tensor([ 623., 1020., 1082., 1300.,  866., 1117., 1058., 1499.,  729.,  706.])\n",
      "14 0.1402\n",
      "tensor([ 624., 1019., 1080., 1288.,  867., 1123., 1056., 1492.,  745.,  706.])\n",
      "15 0.1405\n",
      "tensor([ 624., 1014., 1073., 1267.,  873., 1137., 1053., 1483.,  771.,  705.])\n",
      "16 0.1413\n",
      "tensor([ 625.,  998., 1071., 1239.,  877., 1139., 1051., 1480.,  816.,  704.])\n",
      "17 0.1415\n",
      "tensor([ 625.,  981., 1067., 1209.,  875., 1142., 1052., 1484.,  862.,  703.])\n",
      "18 0.1412\n",
      "tensor([ 625.,  941., 1064., 1180.,  876., 1146., 1053., 1485.,  927.,  703.])\n",
      "19 0.1407\n",
      "tensor([ 629.,  920., 1062., 1152.,  874., 1150., 1053., 1485.,  971.,  704.])\n",
      "20 0.1403\n",
      "tensor([ 634.,  893., 1062., 1126.,  871., 1148., 1051., 1485., 1026.,  704.])\n",
      "21 0.1406\n",
      "tensor([ 637.,  887., 1060., 1110.,  869., 1148., 1050., 1483., 1050.,  706.])\n",
      "22 0.1406\n",
      "tensor([ 636.,  881., 1059., 1101.,  871., 1147., 1047., 1484., 1068.,  706.])\n",
      "23 0.1406\n",
      "tensor([ 637.,  874., 1060., 1092.,  870., 1152., 1047., 1483., 1078.,  707.])\n",
      "24 0.1407\n",
      "tensor([ 637.,  867., 1060., 1085.,  869., 1156., 1048., 1482., 1089.,  707.])\n",
      "25 0.1407\n",
      "tensor([ 637.,  863., 1058., 1086.,  869., 1157., 1049., 1482., 1092.,  707.])\n",
      "26 0.1407\n",
      "tensor([ 636.,  854., 1057., 1085.,  869., 1158., 1049., 1482., 1103.,  707.])\n",
      "27 0.1407\n",
      "tensor([ 637.,  853., 1055., 1085.,  868., 1157., 1049., 1483., 1106.,  707.])\n",
      "28 0.1408\n",
      "tensor([ 636.,  849., 1056., 1084.,  867., 1157., 1049., 1482., 1113.,  707.])\n",
      "29 0.1408\n",
      "tensor([ 635.,  846., 1056., 1083.,  867., 1157., 1049., 1482., 1118.,  707.])\n",
      "30 0.141\n",
      "tensor([ 635.,  840., 1056., 1083.,  867., 1158., 1049., 1482., 1123.,  707.])\n",
      "31 0.1412\n",
      "tensor([ 635.,  835., 1056., 1082.,  866., 1160., 1049., 1482., 1128.,  707.])\n",
      "32 0.141\n",
      "tensor([ 635.,  831., 1056., 1081.,  866., 1159., 1049., 1482., 1134.,  707.])\n",
      "33 0.141\n",
      "tensor([ 635.,  827., 1057., 1077.,  866., 1158., 1049., 1482., 1142.,  707.])\n",
      "34 0.141\n",
      "tensor([ 635.,  827., 1057., 1077.,  867., 1157., 1049., 1482., 1142.,  707.])\n",
      "35 0.1411\n",
      "tensor([ 635.,  827., 1057., 1079.,  867., 1157., 1048., 1482., 1141.,  707.])\n",
      "36 0.1412\n",
      "tensor([ 635.,  827., 1057., 1080.,  867., 1159., 1048., 1482., 1138.,  707.])\n",
      "37 0.1413\n",
      "tensor([ 635.,  827., 1057., 1082.,  867., 1160., 1048., 1482., 1136.,  706.])\n",
      "38 0.1413\n",
      "tensor([ 635.,  827., 1057., 1085.,  867., 1159., 1048., 1482., 1133.,  707.])\n",
      "39 0.1413\n",
      "tensor([ 635.,  826., 1058., 1086.,  867., 1159., 1048., 1481., 1133.,  707.])\n",
      "40 0.1414\n",
      "tensor([ 635.,  825., 1058., 1088.,  867., 1157., 1048., 1482., 1133.,  707.])\n",
      "41 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "42 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "43 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "44 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "45 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "46 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "47 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "48 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "49 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n",
      "50 0.1415\n",
      "tensor([ 635.,  825., 1058., 1091.,  867., 1156., 1048., 1482., 1131.,  707.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1918\n",
      "1 0.1994\n",
      "2 0.199\n",
      "3 0.2009\n",
      "4 0.2058\n",
      "5 0.2091\n",
      "6 0.2126\n",
      "7 0.2139\n",
      "8 0.215\n",
      "9 0.2166\n",
      "10 0.2167\n",
      "11 0.217\n",
      "12 0.2172\n",
      "13 0.2172\n",
      "14 0.2179\n",
      "15 0.2182\n",
      "16 0.218\n",
      "17 0.2181\n",
      "18 0.2182\n",
      "19 0.2187\n",
      "20 0.2197\n",
      "21 0.2206\n",
      "22 0.2218\n",
      "23 0.223\n",
      "24 0.2242\n",
      "25 0.2258\n",
      "26 0.2274\n",
      "27 0.2279\n",
      "28 0.2284\n",
      "29 0.2288\n",
      "30 0.2291\n",
      "31 0.2287\n",
      "32 0.2288\n",
      "33 0.2289\n",
      "34 0.2288\n",
      "35 0.2287\n",
      "36 0.2286\n",
      "37 0.2285\n",
      "38 0.2286\n",
      "39 0.2287\n",
      "40 0.2286\n",
      "41 0.2287\n",
      "42 0.2294\n",
      "43 0.2296\n",
      "44 0.2299\n",
      "45 0.2301\n",
      "46 0.2305\n",
      "47 0.2306\n",
      "48 0.2304\n",
      "49 0.2303\n",
      "50 0.2306\n",
      "51 0.2308\n",
      "52 0.2307\n",
      "53 0.2306\n",
      "54 0.2306\n",
      "55 0.2306\n",
      "56 0.2306\n",
      "57 0.2309\n",
      "58 0.2309\n",
      "59 0.2309\n",
      "60 0.2306\n",
      "61 0.2304\n",
      "62 0.2302\n",
      "63 0.2302\n",
      "64 0.23\n",
      "65 0.23\n",
      "66 0.23\n",
      "67 0.23\n",
      "68 0.23\n",
      "69 0.2299\n",
      "70 0.2301\n",
      "71 0.2301\n",
      "72 0.2299\n",
      "73 0.2299\n",
      "74 0.2299\n",
      "75 0.2299\n",
      "76 0.2299\n",
      "77 0.2299\n",
      "78 0.2299\n",
      "79 0.2299\n",
      "80 0.2299\n",
      "81 0.2299\n",
      "82 0.2299\n",
      "83 0.2299\n",
      "84 0.2299\n",
      "85 0.2299\n",
      "86 0.2299\n",
      "87 0.2299\n",
      "88 0.2299\n",
      "89 0.2299\n",
      "90 0.2299\n",
      "91 0.2299\n",
      "92 0.2299\n",
      "93 0.2299\n",
      "94 0.2299\n",
      "95 0.2299\n",
      "96 0.2299\n",
      "97 0.2299\n",
      "98 0.2299\n",
      "99 0.2299\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.06\n",
      "1 0.011\n",
      "2 0.011\n",
      "3 0.019\n",
      "4 0.024\n",
      "5 0.028\n",
      "6 0.028\n",
      "7 0.028\n",
      "8 0.028\n",
      "9 0.027\n",
      "10 0.029\n",
      "11 0.029\n",
      "12 0.03\n",
      "13 0.031\n",
      "14 0.032\n",
      "15 0.032\n",
      "16 0.032\n",
      "17 0.032\n",
      "18 0.032\n",
      "19 0.033\n",
      "20 0.034\n",
      "21 0.034\n",
      "22 0.034\n",
      "23 0.034\n",
      "24 0.037\n",
      "25 0.037\n",
      "26 0.037\n",
      "27 0.037\n",
      "28 0.037\n",
      "29 0.037\n",
      "30 0.037\n",
      "31 0.037\n",
      "32 0.037\n",
      "33 0.037\n",
      "34 0.037\n",
      "35 0.037\n",
      "36 0.037\n",
      "37 0.037\n",
      "38 0.037\n",
      "39 0.038\n",
      "40 0.038\n",
      "41 0.038\n",
      "42 0.038\n",
      "43 0.038\n",
      "44 0.038\n",
      "45 0.038\n",
      "46 0.038\n",
      "47 0.039\n",
      "48 0.039\n",
      "49 0.039\n",
      "50 0.039\n",
      "51 0.039\n",
      "52 0.039\n",
      "53 0.039\n",
      "54 0.039\n",
      "55 0.039\n",
      "56 0.039\n",
      "57 0.039\n",
      "58 0.039\n",
      "59 0.039\n",
      "60 0.04\n",
      "61 0.04\n",
      "62 0.04\n",
      "63 0.04\n",
      "64 0.04\n",
      "65 0.04\n",
      "66 0.04\n",
      "67 0.04\n",
      "68 0.04\n",
      "69 0.04\n",
      "70 0.04\n",
      "71 0.04\n",
      "72 0.04\n",
      "73 0.04\n",
      "74 0.04\n",
      "75 0.04\n",
      "76 0.04\n",
      "77 0.04\n",
      "78 0.041\n",
      "79 0.041\n",
      "80 0.041\n",
      "81 0.041\n",
      "82 0.041\n",
      "83 0.041\n",
      "84 0.041\n",
      "85 0.041\n",
      "86 0.041\n",
      "87 0.041\n",
      "88 0.041\n",
      "89 0.041\n",
      "90 0.041\n",
      "91 0.041\n",
      "92 0.041\n",
      "93 0.041\n",
      "94 0.042\n",
      "95 0.042\n",
      "96 0.042\n",
      "97 0.042\n",
      "98 0.042\n",
      "99 0.042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.077\n",
      "1 0.053\n",
      "2 0.039\n",
      "3 0.028\n",
      "4 0.025\n",
      "5 0.024\n",
      "6 0.021\n",
      "7 0.024\n",
      "8 0.023\n",
      "9 0.022\n",
      "10 0.021\n",
      "11 0.021\n",
      "12 0.021\n",
      "13 0.02\n",
      "14 0.019\n",
      "15 0.018\n",
      "16 0.016\n",
      "17 0.016\n",
      "18 0.016\n",
      "19 0.016\n",
      "20 0.016\n",
      "21 0.016\n",
      "22 0.016\n",
      "23 0.016\n",
      "24 0.016\n",
      "25 0.016\n",
      "26 0.017\n",
      "27 0.017\n",
      "28 0.017\n",
      "29 0.017\n",
      "30 0.017\n",
      "31 0.017\n",
      "32 0.017\n",
      "33 0.017\n",
      "34 0.017\n",
      "35 0.016\n",
      "36 0.016\n",
      "37 0.016\n",
      "38 0.016\n",
      "39 0.016\n",
      "40 0.017\n",
      "41 0.017\n",
      "42 0.017\n",
      "43 0.017\n",
      "44 0.017\n",
      "45 0.017\n",
      "46 0.017\n",
      "47 0.017\n",
      "48 0.017\n",
      "49 0.017\n",
      "50 0.017\n",
      "51 0.017\n",
      "52 0.017\n",
      "53 0.017\n",
      "54 0.017\n",
      "55 0.017\n",
      "56 0.017\n",
      "57 0.017\n",
      "58 0.017\n",
      "59 0.017\n",
      "60 0.017\n",
      "61 0.017\n",
      "62 0.017\n",
      "63 0.017\n",
      "64 0.017\n",
      "65 0.017\n",
      "66 0.017\n",
      "67 0.017\n",
      "68 0.017\n",
      "69 0.017\n",
      "70 0.017\n",
      "71 0.017\n",
      "72 0.018\n",
      "73 0.018\n",
      "74 0.018\n",
      "75 0.018\n",
      "76 0.018\n",
      "77 0.018\n",
      "78 0.018\n",
      "79 0.018\n",
      "80 0.018\n",
      "81 0.018\n",
      "82 0.018\n",
      "83 0.018\n",
      "84 0.018\n",
      "85 0.018\n",
      "86 0.018\n",
      "87 0.018\n",
      "88 0.018\n",
      "89 0.018\n",
      "90 0.018\n",
      "91 0.018\n",
      "92 0.018\n",
      "93 0.018\n",
      "94 0.018\n",
      "95 0.018\n",
      "96 0.018\n",
      "97 0.018\n",
      "98 0.018\n",
      "99 0.018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "  model.fit(torch.tensor(traindata.astype(np.float32)), epochs=1, init_model=(not epoch))\n",
    "\n",
    "  ypred = model(torch.tensor(traindata.astype(np.float32)))\n",
    "  train_acc = (ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)\n",
    "\n",
    "  print(epoch, train_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model(torch.tensor(traindata.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 2, 9, 4, 6, 3, 5, 8, 5, 9, 8, 7, 1, 3, 5, 6, 8, 4, 3, 6, 9, 2, 9, 4,\n",
       "        3, 8, 6, 8, 1, 9, 0, 4, 3, 6, 2, 7, 3, 2, 6, 3, 5, 4, 6, 6, 0, 6, 4, 7,\n",
       "        1, 8, 8, 2, 6, 9, 6, 4, 1, 6, 6, 4, 1, 9, 3, 2, 3, 7, 3, 4, 1, 1, 5, 9,\n",
       "        5, 3, 8, 2, 0, 4, 4, 9, 1, 2, 3, 3, 6, 4, 1, 6, 1, 9, 3, 6, 6, 3, 4, 2,\n",
       "        6, 4, 8, 4, 0, 6, 5, 6, 5, 4, 3, 8, 1, 3, 6, 8, 5, 4, 2, 9, 6, 8, 2, 2,\n",
       "        1, 1, 4, 6, 5, 4, 3, 9, 5, 3, 8, 9, 5, 6, 0, 8, 8, 4, 1, 9, 6, 9, 6, 4,\n",
       "        0, 7, 4, 3, 6, 8, 5, 3, 5, 6, 6, 3, 2, 8, 1, 4, 8, 8, 6, 9, 9, 3, 9, 6,\n",
       "        4, 2, 6, 4, 6, 7, 5, 7, 6, 4, 2, 8, 5, 8, 1, 6, 5, 6, 3, 8, 6, 0, 5, 7,\n",
       "        2, 6, 6, 6, 6, 4, 1, 6, 5, 4, 4, 8, 3, 4, 1, 8, 5, 1, 1, 5, 5, 3, 6, 8,\n",
       "        1, 9, 3, 2, 1, 3, 1, 6, 8, 8, 6, 6, 1, 1, 6, 5, 3, 3, 1, 8, 7, 9, 3, 7,\n",
       "        5, 3, 8, 6, 1, 4, 1, 6, 5, 1, 6, 5, 5, 3, 1, 8, 4, 9, 6, 7, 2, 3, 2, 6,\n",
       "        6, 4, 1, 6, 6, 4, 5, 9, 6, 7, 3, 9, 5, 3, 3, 8, 6, 8, 6, 1, 1, 6, 3, 7,\n",
       "        6, 9, 5, 8, 3, 2, 9, 4, 2, 9, 1, 3, 4, 6, 3, 2, 6, 6, 1, 6, 3, 4, 5, 3,\n",
       "        0, 6, 9, 4, 1, 3, 4, 9, 1, 8, 6, 3, 6, 3, 2, 8, 2, 9, 8, 3, 1, 1, 6, 7,\n",
       "        6, 6, 9, 3, 1, 8, 6, 4, 6, 4, 8, 2, 4, 6, 6, 4, 1, 6, 6, 4, 8, 4, 5, 2,\n",
       "        5, 8, 6, 9, 6, 3, 5, 3, 5, 9, 5, 6, 6, 9, 6, 3, 5, 6, 0, 9, 6, 3, 5, 6,\n",
       "        6, 3, 1, 6, 3, 6, 4, 2, 8, 4, 5, 3, 8, 4, 5, 2, 3, 3, 9, 7, 1, 8, 5, 7,\n",
       "        5, 9, 4, 6, 6, 9, 3, 4, 4, 7, 7, 6, 8, 3, 6, 6, 0, 8, 6, 2, 6, 1, 3, 3,\n",
       "        0, 8, 6, 2, 6, 7, 6, 4, 1, 6, 6, 4, 5, 4, 1, 4, 4, 3, 5, 2, 1, 2, 5, 4,\n",
       "        4, 2, 1, 6, 6, 9, 2, 7, 1, 3, 4, 6, 1, 4, 5, 6, 5, 2, 2, 4, 6, 2, 6, 8,\n",
       "        1, 9, 6, 0, 5, 2, 1, 9, 0, 2, 8, 4, 4, 3, 1, 8, 2, 4, 3, 4, 6, 9, 5, 4,\n",
       "        8, 6, 3, 4, 4, 4, 4, 4, 6, 7, 8, 2, 1, 3, 6, 2, 6, 6, 6, 7, 1, 9, 1, 7,\n",
       "        0, 9, 0, 9, 0, 4, 3, 4, 3, 7, 4, 4, 0, 9, 2, 7, 8, 4, 8, 3, 8, 8, 6, 2,\n",
       "        5, 4, 1, 2, 5, 8, 0, 4, 4, 8, 6, 3, 6, 3, 6, 6, 4, 9, 3, 4, 5, 4, 5, 4,\n",
       "        6, 2, 3, 7, 6, 8, 1, 4, 3, 9, 6, 4, 4, 9, 6, 2, 3, 4, 1, 9, 1, 3, 3, 6,\n",
       "        6, 9, 1, 2, 5, 9, 9, 3, 6, 4, 6, 4, 1, 8, 7, 4, 6, 6, 5, 3, 1, 9, 1, 3,\n",
       "        6, 2, 9, 6, 1, 8, 5, 9, 6, 2, 6, 9, 6, 4, 5, 2, 6, 4, 3, 8, 4, 8, 4, 9,\n",
       "        5, 3, 5, 6, 8, 7, 6, 9, 2, 4, 3, 4, 3, 9, 1, 9, 6, 3, 3, 7, 1, 2, 1, 4,\n",
       "        3, 3, 5, 8, 5, 6, 5, 2, 9, 3, 6, 6, 3, 4, 6, 6, 5, 2, 1, 4, 6, 4, 5, 8,\n",
       "        4, 9, 4, 2, 9, 3, 2, 6, 1, 4, 6, 6, 5, 2, 5, 4, 2, 3, 5, 8, 3, 9, 6, 2,\n",
       "        5, 3, 1, 6, 6, 4, 0, 6, 6, 9, 6, 8, 4, 2, 0, 3, 1, 3, 5, 3, 8, 9, 9, 2,\n",
       "        6, 2, 5, 4, 1, 9, 6, 2, 8, 6, 6, 9, 6, 2, 4, 3, 1, 4, 3, 6, 6, 4, 4, 8,\n",
       "        1, 4, 6, 2, 6, 6, 2, 7, 3, 4, 6, 4, 5, 2, 6, 4, 8, 3, 6, 2, 3, 8, 2, 4,\n",
       "        1, 6, 3, 6, 4, 9, 6, 2, 6, 9, 3, 6, 9, 2, 6, 4, 5, 4, 3, 8, 6, 4, 4, 2,\n",
       "        3, 4, 2, 6, 6, 4, 6, 4, 6, 2, 6, 9, 1, 3, 8, 4, 8, 4, 9, 4, 1, 2, 5, 6,\n",
       "        8, 3, 1, 8, 2, 2, 1, 9, 6, 2, 3, 9, 3, 6, 6, 9, 8, 8, 4, 2, 2, 8, 0, 0,\n",
       "        5, 4, 1, 8, 6, 2, 5, 4, 1, 2, 8, 8, 5, 9, 8, 7, 6, 3, 1, 6, 4, 4, 1, 6,\n",
       "        6, 2, 8, 4, 5, 2, 6, 8, 9, 9, 6, 7, 6, 3, 2, 2, 6, 4, 0, 2, 6, 8, 1, 6,\n",
       "        8, 4, 9, 7, 3, 2, 4, 4, 5, 7, 5, 4, 1, 4, 9, 2, 6, 6, 6, 2, 6, 9, 6, 7,\n",
       "        5, 9, 4, 3, 6, 4, 6, 3, 3, 9, 4, 7, 4, 2, 6, 4, 1, 8, 6, 3, 8, 2, 3, 4,\n",
       "        1, 4, 6, 4, 7, 2, 1, 9, 6, 6, 1, 9, 6, 3, 0, 8, 4, 3, 5, 2, 6, 6, 5, 8,\n",
       "        1, 7, 3, 9, 9, 2, 9, 6, 8, 4, 6, 9, 3, 2, 1, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ypred == torch.tensor(trainlabels)).sum().item() / len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bf9375872625b9969ad2a164b0e1bb1ff57dc43ce6d3e9b7d00df6c4b93696e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
